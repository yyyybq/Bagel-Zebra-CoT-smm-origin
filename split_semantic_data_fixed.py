import json
import re
from math import ceil
from pathlib import Path

# é…ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
BASE_DIR = Path("/lustre/fsw/portfolios/nvr/users/ymingli/projects/ljh")
VIEWS_TO_PROCESS = [1, 3, 5, 7]  # è¦å¤„ç†çš„è§†è§’åˆ—è¡¨

# Benchmarkåœºæ™¯åˆ—è¡¨ (ä»benchæ–‡ä»¶å¤¹ä¸­æå–çš„100ä¸ªåœºæ™¯)
BENCH_SCENES = {
    ("category/animal/cat", "001"),
    ("category/animal/dog", "002"),
    ("category/animal/dog", "003"),
    ("category/animal/dog", "005"),
    ("category/animal/dog", "007"),
    ("category/animal/dog", "009"),
    ("category/animal/dog", "011"),
    ("category/animal/dog", "013"),
    ("category/animal/dog", "015"),
    ("category/animal/dog", "018"),
    ("category/animal/duck", "001"),
    ("category/animal/duck", "002"),
    ("category/animal/duck", "007"),
    ("category/animal/elephant", "003"),
    ("category/animal/fish", "003"),
    ("category/animal/frog", "002"),
    ("category/animal/giraffe", "002"),
    ("category/animal/giraffe", "003"),
    ("category/animal/giraffe", "005"),
    ("category/animal/giraffe_working", "002"),
    ("category/animal/giraffe_working", "003"),
    ("category/animal/giraffe_working", "005"),
    ("category/animal/horse", "001"),
    ("category/animal/horse", "003"),
    ("category/animal/llama", "003"),
    ("category/animal/llama", "004"),
    ("category/animal/llama", "006"),
    ("category/animal/penguin", "002"),
    ("category/animal/snail", "001"),
    ("category/animal/snail", "003"),
    ("category/building/bridge", "003"),
    ("category/building/bridge", "007"),
    ("category/building/castle", "008"),
    ("category/building/castle", "011"),
    ("category/building/castle", "013"),
    ("category/building/factory", "001"),
    ("category/building/factory", "007"),
    ("category/building/gate", "002"),
    ("category/building/gate", "004"),
    ("category/building/gate", "006"),
    ("category/building/gate", "007"),
    ("category/building/gate", "009"),
    ("category/building/house", "002"),
    ("category/building/house", "007"),
    ("category/building/house", "008"),
    ("category/building/house", "011"),
    ("category/building/house", "012"),
    ("category/building/house", "014"),
    ("category/building/house", "015"),
    ("category/building/house", "017"),
    ("category/building/monument", "001"),
    ("category/building/monument", "004"),
    ("category/building/monument", "015"),
    ("category/building/nest", "002"),
    ("category/building/platform", "004"),
    ("category/building/pyramid", "002"),
    ("category/building/skyscraper", "001"),
    ("category/building/skyscraper", "004"),
    ("category/building/skyscraper", "007"),
    ("category/building/skyscraper", "008"),
    ("category/building/tower", "001"),
    ("category/building/tower", "004"),
    ("category/furniture/camera", "002"),
    ("category/furniture/chimney", "002"),
    ("category/furniture/dining_table", "001"),
    ("category/furniture/sofa", "002"),
    ("category/furniture/sofa", "006"),
    ("category/furniture/sofa", "007"),
    ("category/plant/flower", "001"),
    ("category/plant/flower", "004"),
    ("category/plant/tree", "005"),
    ("category/scenes/scene", "002"),
    ("category/scenes/scene", "003"),
    ("category/scenes/scene", "029"),
    ("category/scenes/scene", "031"),
    ("category/scenes/scene", "051"),
    ("category/scenes/scene", "056"),
    ("category/scenes/scene", "058"),
    ("category/traffic/bulldozer", "002"),
    ("category/traffic/car", "002"),
    ("category/traffic/car", "006"),
    ("category/traffic/car", "007"),
    ("category/traffic/car", "011"),
    ("category/traffic/excavator", "002"),
    ("category/traffic/housecar", "002"),
    ("category/traffic/rocket", "003"),
    ("category/traffic/rocket", "004"),
    ("category/traffic/rocket", "007"),
    ("category/traffic/rocket", "009"),
    ("category/traffic/rocket", "010"),
    ("category/traffic/rocket", "012"),
    ("category/traffic/rocket", "013"),
    ("category/traffic/tanker", "001"),
    ("category/traffic/tanker", "002"),
    ("category/traffic/tanker", "004"),
    ("category/traffic/tank", "001"),
    ("category/traffic/truck", "002"),
    ("category/traffic/truck", "006"),
    ("category/traffic/truck", "008"),
    ("category/traffic/truck", "009"),
}

pat_problem = re.compile(r"^problem_image_(\d+)$")
pat_reasoning = re.compile(r"^reasoning_image_(\d+)$")

def collect_problem_keys(obj):
    """æ”¶é›†å¹¶æ’åºæ‰€æœ‰problem_image_*é”®"""
    ks = []
    for k in obj.keys():
        m = pat_problem.match(k)
        if m:
            ks.append((int(m.group(1)), k))
    return [k for _, k in sorted(ks, key=lambda x: x[0])]

def collect_reasoning_keys(obj):
    """æ”¶é›†å¹¶æ’åºæ‰€æœ‰reasoning_image_*é”®"""
    ks = []
    for k in obj.keys():
        m = pat_reasoning.match(k)
        if m:
            ks.append((int(m.group(1)), k))
    return [k for _, k in sorted(ks, key=lambda x: x[0])]

def split_reasoning_by_thought(reasoning_text: str):
    """æŒ‰THOUGHTåˆ†å‰²æ¨ç†æ–‡æœ¬ï¼Œä¿æŒæ¯ä¸ªTHOUGHTå®Œæ•´
    
    è¿”å›çš„chunksåˆ—è¡¨ï¼š
    - å¦‚æœæœ‰THOUGHT 0: chunks = [THOUGHT 0, THOUGHT 1, THOUGHT 2, ..., THOUGHT N]
    - æ¯ä¸ªTHOUGHTåŒ…å«å®Œæ•´çš„æ–‡æœ¬ï¼ŒåŒ…æ‹¬å…¶å¼•ç”¨çš„reasoning_image
    """
    # ä½¿ç”¨THOUGHTä½œä¸ºåˆ†éš”ç¬¦è¿›è¡Œåˆ†å‰²
    # åˆ†å‰²åä¼šå¾—åˆ°ï¼š['', ' 0: ...', ' 1: ...', ...]
    parts = re.split(r'THOUGHT\s+', reasoning_text)
    
    if len(parts) <= 1:
        return [reasoning_text] if reasoning_text.strip() else []
    
    chunks = []
    # parts[0]æ˜¯ç©ºå­—ç¬¦ä¸²ï¼ˆTHOUGHTä¹‹å‰çš„å†…å®¹ï¼Œåº”è¯¥ä¸ºç©ºï¼‰
    # parts[1:]æ˜¯æ¯ä¸ªTHOUGHTçš„å†…å®¹ï¼ˆä¸åŒ…æ‹¬"THOUGHT"å…³é”®å­—æœ¬èº«ï¼‰
    for i, part in enumerate(parts[1:]):
        # é‡æ–°æ·»åŠ "THOUGHT"å…³é”®å­—å’Œç¼–å·
        chunk = f"THOUGHT {part.strip()}"
        chunks.append(chunk)
    
    return chunks

def renumber_thoughts(text: str, start_num: int = 0):
    """é‡æ–°ç¼–å·THOUGHT"""
    counter = [start_num]
    def replacer(match):
        result = f"THOUGHT {counter[0]}:"
        counter[0] += 1
        return result
    return re.sub(r'THOUGHT\s+\d+:', replacer, text)

def renumber_steps(text: str, start_num: int = 1):
    """é‡æ–°ç¼–å·Step"""
    counter = [start_num]
    def replacer(match):
        result = f"Step {counter[0]}:"
        counter[0] += 1
        return result
    return re.sub(r'Step\s+\d+:', replacer, text)

def renumber_reasoning_images(text: str, old_to_new_map: dict):
    """é‡æ–°ç¼–å·reasoning_imageå¼•ç”¨"""
    def replacer(match):
        old_num = int(match.group(1))
        new_num = old_to_new_map.get(old_num, old_num)
        return f"<image_start>[reasoning_image_{new_num}]<image_end>"
    return re.sub(r'<image_start>\[reasoning_image_(\d+)\]<image_end>', replacer, text)

def renumber_problem_images(text: str, old_to_new_map: dict):
    """é‡æ–°ç¼–å·problem_imageå¼•ç”¨"""
    def replacer(match):
        old_num = int(match.group(1))
        new_num = old_to_new_map.get(old_num, old_num)
        if new_num is None:
            return match.group(0)  # ä¿æŒä¸å˜
        return f"<image_start>[problem_image_{new_num}]<image_end>"
    return re.sub(r'<image_start>\[problem_image_(\d+)\]<image_end>', replacer, text)

def update_block_count(text: str, new_count: int):
    """æ›´æ–°ç§¯æœ¨æ€»æ•°"""
    return re.sub(r'There are a total of \d+ distinct blocks', 
                  f'There are a total of {new_count} distinct blocks', text)

def get_block_description_from_step(chunk: str):
    """ä»æ­¥éª¤æ–‡æœ¬ä¸­æå–ç§¯æœ¨æè¿°"""
    patterns = [
        r'place a (.*?) block',
        r'add (?:the )?(.*?)(?: block)?\s+(?:on top of|to)',
        r'Finally, place a (.*?)(?: block)?\s+',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, chunk, re.IGNORECASE)
        if match:
            desc = match.group(1).strip()
            desc = re.sub(r'\s+', ' ', desc)
            return desc
    
    return "the next block"

def process_line(obj):
    """
    å¤„ç†å•è¡Œæ•°æ®ï¼Œå†³å®šæ˜¯å¦éœ€è¦åˆ†å‰²
    è¿”å›ï¼š
      - None: è·³è¿‡è¯¥è¡Œï¼ˆ2*x + y > 22ï¼‰
      - [obj]: ä¿æŒåŸæ ·ï¼ˆx+y <= 11ï¼‰
      - [obj1, obj2]: åˆ†å‰²åçš„ä¸¤ä¸ªå¯¹è±¡
    """
    problem_keys = collect_problem_keys(obj)
    reasoning_keys = collect_reasoning_keys(obj)
    
    x = len(problem_keys)
    y = len(reasoning_keys)
    
    # è§„åˆ™1: æ¨ç†æ­¥æ•° <= 10ï¼Œä¿æŒåŸæ ·
    if y <= 10:
        return [obj]
    
    # è§„åˆ™2: æ¨ç†æ­¥æ•° > 20ï¼Œè·³è¿‡ï¼ˆå¤ªé•¿ï¼‰
    if y > 20:
        return None
    
    # è§„åˆ™3: éœ€è¦åˆ†å‰² (10 < y <= 20)
    if y == 0 or "Question" not in obj or "Text Reasoning Trace" not in obj:
        return [obj]
    
    # åˆ†å‰²ç‚¹ï¼šä¿ç•™å‰kä¸ªreasoning steps
    k = ceil(y / 2)
    k = max(1, min(k, y))
    
    # è§£ææ¨ç†æ–‡æœ¬
    reasoning_text = obj.get("Text Reasoning Trace", "")
    chunks = split_reasoning_by_thought(reasoning_text)
    
    if not chunks:
        return [obj]
    
    # ç¡®å®šTHOUGHT 0çš„ä½ç½®
    has_thought0 = chunks[0].startswith("THOUGHT 0:")
    
    # chunksåŒ…å«æ‰€æœ‰çš„THOUGHTï¼ˆåŒ…æ‹¬THOUGHT 0å’ŒTHOUGHT 1-yï¼‰
    # ä½†reasoning_imageåªæœ‰1åˆ°y-1
    # å¦‚æœæœ‰THOUGHT 0ï¼Œchunks = [THOUGHT 0, THOUGHT 1, ..., THOUGHT y-1]ï¼Œå…±yä¸ª
    # æˆ‘ä»¬éœ€è¦ä¿ç•™ THOUGHT 0 + THOUGHT 1 åˆ° THOUGHT k-1ï¼ˆå› ä¸ºTHOUGHT kå¯¹åº”reasoning_image_kï¼‰
    
    if has_thought0:
        # chunks[0] = THOUGHT 0
        # chunks[1] = THOUGHT 1 (å¯¹åº” reasoning_image_1)
        # chunks[k] = THOUGHT k (å¯¹åº” reasoning_image_k)
        # æˆ‘ä»¬ä¿ç•™ chunks[0] åˆ° chunks[k]ï¼ˆå…±k+1ä¸ªï¼‰ï¼Œå³THOUGHT 0åˆ°THOUGHT k
        first_chunks = chunks[:k+1]  # THOUGHT 0 + THOUGHT 1-k
        second_chunks = chunks[k+1:]  # THOUGHT (k+1) to end
    else:
        # æ²¡æœ‰THOUGHT 0çš„æƒ…å†µï¼ˆæ—§æ•°æ®æ ¼å¼ï¼‰
        first_chunks = chunks[:k]
        second_chunks = chunks[k:]
    
    # ========== æ„å»ºç¬¬ä¸€éƒ¨åˆ† ==========
    first_obj = {}
    
    # Questionä¿æŒä¸å˜
    first_obj["Question"] = obj.get("Question", "")
    
    # Text Reasoning Trace
    first_obj["Text Reasoning Trace"] = " ".join(first_chunks).strip()
    
    # âœ… ç¬¬ä¸€éƒ¨åˆ†æœ‰Final Answerï¼ˆä½œä¸ºç»“æŸç¬¦ï¼‰
    if "Final Answer" in obj:
        first_obj["Final Answer"] = obj["Final Answer"]
    
    # ä¿ç•™å€™é€‰ç§¯æœ¨çš„problem_imageï¼ˆ1åˆ°nï¼‰
    for i, pk in enumerate(problem_keys):
        if i < len(problem_keys) - 2:  # åªä¿ç•™å€™é€‰ç§¯æœ¨ï¼Œä¸åŒ…æ‹¬final_imageå’Œstep0_image
            first_obj[pk] = obj[pk]
    
    # ç¬¬ä¸€éƒ¨åˆ†çš„ç›®æ ‡å›¾ç‰‡åº”è¯¥æ˜¯step kï¼Œè€Œä¸æ˜¯æœ€ç»ˆçŠ¶æ€
    step_k_key = f"reasoning_image_{k}"
    if step_k_key in obj:
        # problem_image_{n+1} = step kçš„å›¾ç‰‡ï¼ˆç¬¬ä¸€éƒ¨åˆ†çš„ç›®æ ‡ï¼‰
        final_image_key = problem_keys[-2]  # å€’æ•°ç¬¬äºŒä¸ªæ˜¯final_image
        first_obj[final_image_key] = obj[step_k_key]
    
    # ä¿ç•™step 0çš„å›¾ç‰‡
    step0_key = problem_keys[-1]  # æœ€åä¸€ä¸ªæ˜¯step0_image
    first_obj[step0_key] = obj[step0_key]
    
    # ä¿ç•™å‰kä¸ªreasoning_image_*ï¼ˆåŒ…æ‹¬ç¬¬kä¸ªï¼Œå› ä¸ºText Reasoning Traceä¸­ä¼šå¼•ç”¨å®ƒï¼‰
    for rk in reasoning_keys:
        m = pat_reasoning.match(rk)
        if m:
            idx = int(m.group(1))
            if idx <= k:  # ä¿ç•™1åˆ°kçš„æ‰€æœ‰reasoning_image
                first_obj[rk] = obj[rk]
    
    # ========== æ„å»ºç¬¬äºŒéƒ¨åˆ† ==========
    second_obj = {}
    
    # æå–æœ€åä¸€æ­¥çš„ç§¯æœ¨æè¿°
    if first_chunks:
        last_chunk = first_chunks[-1]
        block_desc = get_block_description_from_step(last_chunk)
    else:
        block_desc = "blocks"
    
    # è®¡ç®—å‰©ä½™ç§¯æœ¨æ•°é‡ = å‰©ä½™reasoningæ­¥éª¤æ•°
    remaining_blocks = y - k
    
    # æ„å»ºæ–°çš„Question
    original_q = obj.get("Question", "")
    
    if "Step 0 has been completed:" in original_q:
        # æå–åŸå§‹Questionçš„å€™é€‰ç§¯æœ¨éƒ¨åˆ†ï¼ˆä¿æŒä¸å˜ï¼‰
        # æ ¼å¼ï¼šä»å¼€å¤´åˆ°"Step 0 has been completed:"ä¹‹å‰
        step0_match = re.search(r'(.*?)(Step 0 has been completed:.*)', original_q, re.DOTALL)
        if step0_match:
            # ä¿ç•™åŸå§‹çš„å€™é€‰ç§¯æœ¨åˆ—è¡¨éƒ¨åˆ†
            candidate_blocks_part = step0_match.group(1)
            
            # æ„å»ºæ–°çš„Step k completedéƒ¨åˆ†
            # æ³¨æ„ï¼šåœ¨ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œstep kçš„å›¾ç‰‡å·²ç»è¢«ç§»åˆ°problem_image_{n+2}ä½ç½®
            last_problem_idx = len(problem_keys)  # æœ€åä¸€ä¸ªproblem_imageçš„ç´¢å¼•
            new_step_part = (
                f"Previous {k} steps have been completed. "
                f"The image after {k} steps is provided: <image_start>[problem_image_{last_problem_idx}]<image_end>. "
            )
            
            second_obj["Question"] = candidate_blocks_part + new_step_part
        else:
            # Fallback
            second_obj["Question"] = original_q
    else:
        # Fallback
        second_obj["Question"] = original_q
    
    # âœ… ä¿ç•™æ‰€æœ‰å€™é€‰ç§¯æœ¨å›¾ç‰‡ï¼ˆ1åˆ°nï¼‰
    num_blocks = len(problem_keys) - 2  # å‡å»final_imageå’Œstep0_image
    
    for i, pk in enumerate(problem_keys):
        if i < len(problem_keys) - 2:  # ä¿ç•™å€™é€‰ç§¯æœ¨
            second_obj[pk] = obj[pk]
    
    # ç¬¬äºŒéƒ¨åˆ†çš„ç›®æ ‡å›¾ç‰‡åº”è¯¥æ˜¯åŸå§‹çš„æœ€ç»ˆçŠ¶æ€ï¼ˆstep yï¼‰
    final_image_key = problem_keys[-2]  # å€’æ•°ç¬¬äºŒä¸ªæ˜¯final_image
    second_obj[final_image_key] = obj[final_image_key]  # ä¿ç•™åŸå§‹çš„æœ€ç»ˆç›®æ ‡
    
    # æ·»åŠ reasoning_image_kä½œä¸ºæ–°çš„èµ·å§‹çŠ¶æ€ï¼ˆæ›¿ä»£åŸæ¥çš„step 0ï¼‰
    step_k_key = f"reasoning_image_{k}"
    if step_k_key in obj:
        # ä½¿ç”¨problem_imageçš„æœ€åä¸€ä¸ªkeyä½ç½®ï¼ˆåŸæ¥çš„step 0ä½ç½®ï¼‰
        last_problem_key = problem_keys[-1]
        second_obj[last_problem_key] = obj[step_k_key]
    
    # Text Reasoning Trace: å‰©ä½™çš„æ¨ç†æ­¥éª¤ï¼Œé‡æ–°ç¼–å·
    second_reasoning = " ".join(second_chunks).strip()
    
    # åˆ›å»ºreasoning_imageçš„æ˜ å°„
    old_to_new = {}
    new_r_idx = 1
    for rk in reasoning_keys:
        m = pat_reasoning.match(rk)
        if m:
            old_idx = int(m.group(1))
            if old_idx > k:
                old_to_new[old_idx] = new_r_idx
                new_key = f"reasoning_image_{new_r_idx}"
                second_obj[new_key] = obj[rk]
                new_r_idx += 1
    
    # é‡æ–°ç¼–å·THOUGHT, Step, reasoning_image
    second_reasoning = renumber_thoughts(second_reasoning, start_num=0)
    second_reasoning = renumber_steps(second_reasoning, start_num=1)
    second_reasoning = renumber_reasoning_images(second_reasoning, old_to_new)
    
    # âœ… ä¸ä¿®æ”¹THOUGHT 0ä¸­çš„ç§¯æœ¨æ€»æ•°ï¼ˆä¿æŒä¸åŸå§‹ä¸€è‡´ï¼‰
    # second_reasoning = update_block_count(second_reasoning, remaining_blocks)  # æ³¨é‡Šæ‰è¿™è¡Œ
    
    second_obj["Text Reasoning Trace"] = second_reasoning
    
    # âœ… ç¬¬äºŒéƒ¨åˆ†ä¹Ÿæœ‰Final Answer
    if "Final Answer" in obj:
        second_obj["Final Answer"] = obj["Final Answer"]
    
    # ä¿ç•™å…ƒæ•°æ®
    for meta_key in ["category", "subcategory", "scene_name"]:
        if meta_key in obj:
            first_obj[meta_key] = obj[meta_key]
            second_obj[meta_key] = obj[meta_key]
    
    return [first_obj, second_obj]

def process_file(input_path: Path):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶è¿”å›æ‰€æœ‰æ•°æ®å’ŒçŸ­æ•°æ®"""
    total = 0
    skipped = 0
    split_count = 0
    all_data = []
    short_data = []  # åªåŒ…å«åŸå§‹æ¨ç†æ­¥æ•°<11çš„æ•°æ®
    
    with input_path.open("r", encoding="utf-8") as fin:
        for line_num, line in enumerate(fin, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                obj = json.loads(line)
            except json.JSONDecodeError:
                print(f"âš ï¸ Line {line_num} JSON decode error â€” skip.")
                skipped += 1
                continue
            
            total += 1
            
            # åœ¨å¤„ç†ä¹‹å‰ï¼Œæ£€æŸ¥åŸå§‹æ¨ç†æ­¥æ•°
            original_reasoning_keys = collect_reasoning_keys(obj)
            original_y = len(original_reasoning_keys)
            
            result = process_line(obj)
            
            if result is None:
                skipped += 1
                continue
            
            if len(result) == 1:
                all_data.append(result[0])
                # åªæœ‰åŸå§‹æ¨ç†æ­¥æ•°<11çš„æ‰åŠ å…¥short_data
                if original_y < 11:
                    short_data.append(result[0])
            else:
                # åˆ†å‰²æˆä¸¤éƒ¨åˆ†
                all_data.append(result[0])
                all_data.append(result[1])
                # åŸå§‹æ•°æ®è¢«åˆ†å‰²äº†ï¼Œè¯´æ˜åŸå§‹æ¨ç†æ­¥æ•°>=11ï¼Œä¸åŠ å…¥short_data
                split_count += 1
    
    return all_data, short_data, total, skipped, split_count


def main():
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    train_dir = BASE_DIR / "train"
    bench_dir = BASE_DIR / "bench"
    train_short_dir = BASE_DIR / "train_short"
    train_dir.mkdir(exist_ok=True)
    bench_dir.mkdir(exist_ok=True)
    train_short_dir.mkdir(exist_ok=True)
    
    print(f"Processing {len(VIEWS_TO_PROCESS)} views and all_views file...")
    print(f"Using {len(BENCH_SCENES)} predefined bench scenes\n")
    
    # å¤„ç†æ‰€æœ‰è§†è§’æ–‡ä»¶
    all_files = {
        "all_views": BASE_DIR / "semantic_training_all_views_textfirst.jsonl"
    }
    for view_num in VIEWS_TO_PROCESS:
        all_files[f"view{view_num}"] = BASE_DIR / f"semantic_training_view{view_num}_textfirst.jsonl"
    
    for file_key, input_path in all_files.items():
        if not input_path.exists():
            print(f"âš ï¸ File not found: {input_path}")
            continue
        
        print(f"ğŸ“„ Processing {file_key}: {input_path.name}")
        
        # å¤„ç†æ–‡ä»¶
        all_data, short_data, total, skipped, split_count = process_file(input_path)
        
        # å®šä¹‰æœ€å¤§å›¾ç‰‡æ•°é™åˆ¶
        MAX_IMAGES = 20
        
        print(f"   âœ… Total input lines: {total}")
        print(f"   âœ… Lines written: {len(all_data)}")
        print(f"   âš ï¸ Lines skipped: {skipped}")
        print(f"   ğŸ“Š Lines split into 2 parts: {split_count}")
        print(f"   ğŸ“ Short data (original y<11): {len(short_data)}")
        
        # åˆ’åˆ†trainå’Œbenchï¼ŒåŒæ—¶è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
        train_data = []
        bench_data = []
        train_short_data = []
        filtered_by_images = 0
        print(f"   ğŸ—‘ï¸ Filtered by image count (>{MAX_IMAGES}): {filtered_by_images}")
        
        # åˆ’åˆ†trainå’Œbenchï¼ŒåŒæ—¶è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
        MAX_IMAGES = 20  # æœ€å¤šå…è®¸20å¼ å›¾ç‰‡
        train_data = []
        bench_data = []
        train_short_data = []
        filtered_by_images = 0
        
        for item in all_data:
            # ç»Ÿè®¡å›¾ç‰‡æ•°é‡
            num_images = len([k for k in item.keys() if 'image' in k])
            
            # è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
            if num_images > MAX_IMAGES:
                filtered_by_images += 1
                continue
            
            category = item.get("category", "")
            scene_name = item.get("scene_name", "")
            
            if (category, scene_name) in BENCH_SCENES:
                bench_data.append(item)
            else:
                train_data.append(item)
        
        # train_shortåªåŒ…å«åŸå§‹æ¨ç†æ­¥æ•°<11ä¸”ä¸åœ¨benchä¸­çš„æ•°æ®
        for item in short_data:
            # ç»Ÿè®¡å›¾ç‰‡æ•°é‡
            num_images = len([k for k in item.keys() if 'image' in k])
            
            # è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
            if num_images > MAX_IMAGES:
                continue
            
            category = item.get("category", "")
            scene_name = item.get("scene_name", "")
            
            if (category, scene_name) not in BENCH_SCENES:
                train_short_data.append(item)
        
        # ä¿å­˜trainæ–‡ä»¶
        train_file = train_dir / f"semantic_training_{file_key}_textfirst.jsonl"
        with train_file.open("w", encoding="utf-8") as f:
            for item in train_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        print(f"   âœ… Train set: {len(train_data)} samples â†’ {train_file}")
        
        # ä¿å­˜benchæ–‡ä»¶
        bench_file = bench_dir / f"semantic_training_{file_key}_textfirst.jsonl"
        with bench_file.open("w", encoding="utf-8") as f:
            for item in bench_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        print(f"   âœ… Bench set: {len(bench_data)} samples â†’ {bench_file}")
        
        # ä¿å­˜train_shortæ–‡ä»¶
        train_short_file = train_short_dir / f"semantic_training_{file_key}_textfirst.jsonl"
        with train_short_file.open("w", encoding="utf-8") as f:
            for item in train_short_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        print(f"   âœ… Train short set (y<11): {len(train_short_data)} samples â†’ {train_short_file}")
        print()
    
    print(f"ğŸ‰ All done!")
    print(f"ğŸ“ Train files saved to: {train_dir}")
    print(f"ğŸ“ Bench files saved to: {bench_dir}")
    print(f"ğŸ“ Train short files (y<11) saved to: {train_short_dir}")

if __name__ == "__main__":
    main()
    '''
python split_semantic_data_fixed.py
'''