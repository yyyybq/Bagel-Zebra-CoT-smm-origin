import json
import re
from math import ceil
from pathlib import Path

# é…ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
BASE_DIR = Path("/lustre/fsw/portfolios/nvr/users/ymingli/projects/ljh")
VIEWS_TO_PROCESS = [1, 3, 5, 7]  # è¦å¤„ç†çš„è§†è§’åˆ—è¡¨

# Benchmarkåœºæ™¯åˆ—è¡¨ (ä»benchæ–‡ä»¶å¤¹ä¸­æå–çš„100ä¸ªåœºæ™¯)
BENCH_SCENES = {
    ("category/animal/cat", "001"),
    ("category/animal/dog", "002"),
    ("category/animal/dog", "003"),
    ("category/animal/dog", "005"),
    ("category/animal/dog", "007"),
    ("category/animal/dog", "009"),
    ("category/animal/dog", "011"),
    ("category/animal/dog", "013"),
    ("category/animal/dog", "015"),
    ("category/animal/dog", "018"),
    ("category/animal/duck", "001"),
    ("category/animal/duck", "002"),
    ("category/animal/duck", "007"),
    ("category/animal/elephant", "003"),
    ("category/animal/fish", "003"),
    ("category/animal/frog", "002"),
    ("category/animal/giraffe", "002"),
    ("category/animal/giraffe", "003"),
    ("category/animal/giraffe", "005"),
    ("category/animal/giraffe_working", "002"),
    ("category/animal/giraffe_working", "003"),
    ("category/animal/giraffe_working", "005"),
    ("category/animal/horse", "001"),
    ("category/animal/horse", "003"),
    ("category/animal/llama", "003"),
    ("category/animal/llama", "004"),
    ("category/animal/llama", "006"),
    ("category/animal/penguin", "002"),
    ("category/animal/snail", "001"),
    ("category/animal/snail", "003"),
    ("category/building/bridge", "003"),
    ("category/building/bridge", "007"),
    ("category/building/castle", "008"),
    ("category/building/castle", "011"),
    ("category/building/castle", "013"),
    ("category/building/factory", "001"),
    ("category/building/factory", "007"),
    ("category/building/gate", "002"),
    ("category/building/gate", "004"),
    ("category/building/gate", "006"),
    ("category/building/gate", "007"),
    ("category/building/gate", "009"),
    ("category/building/house", "002"),
    ("category/building/house", "007"),
    ("category/building/house", "008"),
    ("category/building/house", "011"),
    ("category/building/house", "012"),
    ("category/building/house", "014"),
    ("category/building/house", "015"),
    ("category/building/house", "017"),
    ("category/building/monument", "001"),
    ("category/building/monument", "004"),
    ("category/building/monument", "015"),
    ("category/building/nest", "002"),
    ("category/building/platform", "004"),
    ("category/building/pyramid", "002"),
    ("category/building/skyscraper", "001"),
    ("category/building/skyscraper", "004"),
    ("category/building/skyscraper", "007"),
    ("category/building/skyscraper", "008"),
    ("category/building/tower", "001"),
    ("category/building/tower", "004"),
    ("category/furniture/camera", "002"),
    ("category/furniture/chimney", "002"),
    ("category/furniture/dining_table", "001"),
    ("category/furniture/sofa", "002"),
    ("category/furniture/sofa", "006"),
    ("category/furniture/sofa", "007"),
    ("category/plant/flower", "001"),
    ("category/plant/flower", "004"),
    ("category/plant/tree", "005"),
    ("category/scene", "002"),
    ("category/scene", "003"),
    ("category/scene", "029"),
    ("category/scene", "031"),
    ("category/scene", "051"),
    ("category/scene", "056"),
    ("category/scene", "058"),
    ("category/traffic/bulldozer", "002"),
    ("category/traffic/car", "002"),
    ("category/traffic/car", "006"),
    ("category/traffic/car", "007"),
    ("category/traffic/car", "011"),
    ("category/traffic/excavator", "002"),
    ("category/traffic/housecar", "002"),
    ("category/traffic/rocket", "003"),
    ("category/traffic/rocket", "004"),
    ("category/traffic/rocket", "007"),
    ("category/traffic/rocket", "009"),
    ("category/traffic/rocket", "010"),
    ("category/traffic/rocket", "012"),
    ("category/traffic/rocket", "013"),
    ("category/traffic/tanker", "001"),
    ("category/traffic/tanker", "002"),
    ("category/traffic/tanker", "004"),
    ("category/traffic/tank", "001"),
    ("category/traffic/truck", "002"),
    ("category/traffic/truck", "006"),
    ("category/traffic/truck", "008"),
    ("category/traffic/truck", "009"),
}

pat_problem = re.compile(r"^problem_image_(\d+)$")
pat_reasoning = re.compile(r"^reasoning_image_(\d+)$")

def collect_problem_keys(obj):
    """æ”¶é›†å¹¶æ’åºæ‰€æœ‰problem_image_*é”®"""
    ks = []
    for k in obj.keys():
        m = pat_problem.match(k)
        if m:
            ks.append((int(m.group(1)), k))
    return [k for _, k in sorted(ks, key=lambda x: x[0])]

def collect_reasoning_keys(obj):
    """æ”¶é›†å¹¶æ’åºæ‰€æœ‰reasoning_image_*é”®"""
    ks = []
    for k in obj.keys():
        m = pat_reasoning.match(k)
        if m:
            ks.append((int(m.group(1)), k))
    return [k for _, k in sorted(ks, key=lambda x: x[0])]

def split_reasoning_by_thought(reasoning_text: str):
    """æŒ‰THOUGHTåˆ†å‰²æ¨ç†æ–‡æœ¬ï¼Œä¿æŒæ¯ä¸ªTHOUGHTå®Œæ•´
    
    è¿”å›çš„chunksåˆ—è¡¨ï¼š
    - å¦‚æœæœ‰THOUGHT 0: chunks = [THOUGHT 0, THOUGHT 1, THOUGHT 2, ..., THOUGHT N]
    - æ¯ä¸ªTHOUGHTåŒ…å«å®Œæ•´çš„æ–‡æœ¬ï¼ŒåŒ…æ‹¬å…¶å¼•ç”¨çš„reasoning_image
    """
    # ä½¿ç”¨THOUGHTä½œä¸ºåˆ†éš”ç¬¦è¿›è¡Œåˆ†å‰²
    # åˆ†å‰²åä¼šå¾—åˆ°ï¼š['', ' 0: ...', ' 1: ...', ...]
    parts = re.split(r'THOUGHT\s+', reasoning_text)
    
    if len(parts) <= 1:
        return [reasoning_text] if reasoning_text.strip() else []
    
    chunks = []
    # parts[0]æ˜¯ç©ºå­—ç¬¦ä¸²ï¼ˆTHOUGHTä¹‹å‰çš„å†…å®¹ï¼Œåº”è¯¥ä¸ºç©ºï¼‰
    # parts[1:]æ˜¯æ¯ä¸ªTHOUGHTçš„å†…å®¹ï¼ˆä¸åŒ…æ‹¬"THOUGHT"å…³é”®å­—æœ¬èº«ï¼‰
    for i, part in enumerate(parts[1:]):
        # é‡æ–°æ·»åŠ "THOUGHT"å…³é”®å­—å’Œç¼–å·
        chunk = f"THOUGHT {part.strip()}"
        chunks.append(chunk)
    
    return chunks

def renumber_thoughts(text: str, start_num: int = 0):
    """é‡æ–°ç¼–å·THOUGHT"""
    counter = [start_num]
    def replacer(match):
        result = f"THOUGHT {counter[0]}:"
        counter[0] += 1
        return result
    return re.sub(r'THOUGHT\s+\d+:', replacer, text)

def renumber_steps(text: str, start_num: int = 1):
    """é‡æ–°ç¼–å·Step"""
    counter = [start_num]
    def replacer(match):
        result = f"Step {counter[0]}:"
        counter[0] += 1
        return result
    return re.sub(r'Step\s+\d+:', replacer, text)

def renumber_reasoning_images(text: str, old_to_new_map: dict):
    """é‡æ–°ç¼–å·reasoning_imageå¼•ç”¨"""
    def replacer(match):
        old_num = int(match.group(1))
        new_num = old_to_new_map.get(old_num, old_num)
        return f"<image_start>[reasoning_image_{new_num}]<image_end>"
    return re.sub(r'<image_start>\[reasoning_image_(\d+)\]<image_end>', replacer, text)

def update_block_count(text: str, new_count: int):
    """æ›´æ–°ç§¯æœ¨æ€»æ•°"""
    return re.sub(r'There are a total of \d+ distinct blocks', 
                  f'There are a total of {new_count} distinct blocks', text)

def get_block_description_from_step(chunk: str):
    """ä»æ­¥éª¤æ–‡æœ¬ä¸­æå–ç§¯æœ¨æè¿°"""
    patterns = [
        r'place a (.*?) block',
        r'add (?:the )?(.*?)(?: block)?\s+(?:on top of|to)',
        r'Finally, place a (.*?)(?: block)?\s+',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, chunk, re.IGNORECASE)
        if match:
            desc = match.group(1).strip()
            desc = re.sub(r'\s+', ' ', desc)
            return desc
    
    return "the next block"

def process_line(obj):
    """
    å¤„ç†å•è¡Œæ•°æ®ï¼ˆminimalç‰ˆæœ¬ï¼šåªæœ‰2å¼ problemå›¾ç‰‡ï¼‰
    
    Minimalç‰ˆæœ¬çš„ç‰¹ç‚¹ï¼š
    - problem_image_1: final state
    - problem_image_2: step 0
    - reasoning_image_1 åˆ° reasoning_image_{y-1}: ä¸­é—´æ­¥éª¤
    
    è¿”å›ï¼š
      - None: è·³è¿‡è¯¥è¡Œï¼ˆy > 20ï¼‰
      - [obj]: ä¿æŒåŸæ ·ï¼ˆy <= 10ï¼‰
      - [obj1, obj2]: åˆ†å‰²åçš„ä¸¤ä¸ªå¯¹è±¡ï¼ˆ10 < y <= 20ï¼‰
    """
    problem_keys = collect_problem_keys(obj)
    reasoning_keys = collect_reasoning_keys(obj)
    
    x = len(problem_keys)  # minimalç‰ˆæœ¬å›ºå®šä¸º2
    y = len(reasoning_keys)
    
    # è§„åˆ™1: æ¨ç†æ­¥æ•° <= 10ï¼Œä¿æŒåŸæ ·
    if y <= 10:
        return [obj]
    
    # è§„åˆ™2: æ¨ç†æ­¥æ•° > 20ï¼Œè·³è¿‡ï¼ˆå¤ªé•¿ï¼‰
    if y > 20:
        return None
    
    # è§„åˆ™3: éœ€è¦åˆ†å‰² (10 < y <= 20)
    if y == 0 or "Question" not in obj or "Text Reasoning Trace" not in obj:
        return [obj]
    
    # åˆ†å‰²ç‚¹ï¼šä¿ç•™å‰kä¸ªreasoning steps
    k = ceil(y / 2)
    k = max(1, min(k, y))
    
    # è§£ææ¨ç†æ–‡æœ¬
    reasoning_text = obj.get("Text Reasoning Trace", "")
    chunks = split_reasoning_by_thought(reasoning_text)
    
    if not chunks:
        return [obj]
    
    # ç¡®å®šTHOUGHT 0çš„ä½ç½®
    has_thought0 = chunks[0].startswith("THOUGHT 0:")
    
    if has_thought0:
        # chunks[0] = THOUGHT 0
        # chunks[k] = THOUGHT k (å¯¹åº” reasoning_image_k)
        # ä¿ç•™ chunks[0] åˆ° chunks[k]ï¼ˆå…±k+1ä¸ªï¼‰
        first_chunks = chunks[:k+1]  # THOUGHT 0 + THOUGHT 1-k
        second_chunks = chunks[k+1:]  # THOUGHT (k+1) to end
    else:
        # æ²¡æœ‰THOUGHT 0çš„æƒ…å†µ
        first_chunks = chunks[:k]
        second_chunks = chunks[k:]
    
    # ========== æ„å»ºç¬¬ä¸€éƒ¨åˆ† ==========
    first_obj = {}
    
    # Questionéœ€è¦ä¿®æ”¹ï¼šfinal stateæ”¹ä¸ºstep k
    original_q = obj.get("Question", "")
    
    # æ›¿æ¢final stateçš„æè¿°
    # åŸå§‹ï¼šan image of the final desired shape: <image_start>[problem_image_1]<image_end>
    # ä¿®æ”¹ä¸ºï¼šan image of the intermediate target (step k): <image_start>[problem_image_1]<image_end>
    first_question = re.sub(
        r'an image of the final desired shape:',
        f'an image of the intermediate target (step {k}):',
        original_q
    )
    first_obj["Question"] = first_question
    
    # Text Reasoning Trace
    first_obj["Text Reasoning Trace"] = " ".join(first_chunks).strip()
    
    # Final Answer
    if "Final Answer" in obj:
        first_obj["Final Answer"] = obj["Final Answer"]
    
    # problem_image_1: æ”¹ä¸ºstep kçš„å›¾ç‰‡
    step_k_key = f"reasoning_image_{k}"
    if step_k_key in obj:
        first_obj["problem_image_1"] = obj[step_k_key]
    
    # problem_image_2: ä¿æŒstep 0
    first_obj["problem_image_2"] = obj["problem_image_2"]
    
    # ä¿ç•™å‰kä¸ªreasoning_image_*
    for rk in reasoning_keys:
        m = pat_reasoning.match(rk)
        if m:
            idx = int(m.group(1))
            if idx <= k:
                first_obj[rk] = obj[rk]
    
    # ========== æ„å»ºç¬¬äºŒéƒ¨åˆ† ==========
    second_obj = {}
    
    # Question: ä¿®æ”¹èµ·å§‹çŠ¶æ€æè¿°
    # åŸå§‹æ ¼å¼ä¸­æœ‰ï¼š"and an image showing the initial state (step 0): <image_start>[problem_image_2]<image_end>"
    # éœ€è¦æ”¹ä¸ºï¼š"Previous {k} steps have been completed. The image after {k} steps is provided: <image_start>[problem_image_2]<image_end>"
    
    second_question = original_q
    
    # æ›¿æ¢step 0çš„æè¿°
    step0_pattern = r'and an image showing the initial state \(step 0\): <image_start>\[problem_image_2\]<image_end>\.'
    replacement = f'and an image showing the state after {k} steps: <image_start>[problem_image_2]<image_end>.'
    second_question = re.sub(step0_pattern, replacement, second_question)
    
    # åŒæ—¶ä¿®æ”¹åç»­çš„æè¿°
    step0_completed_pattern = r'Step 0 has been completed: a (.*?) block has been placed on top of the ground\.'
    second_question = re.sub(
        step0_completed_pattern,
        f'Previous {k} steps have been completed.',
        second_question
    )
    
    # ä¿®æ”¹æœ€åçš„æè¿°
    second_question = re.sub(
        r'I need to imagine and generate images of intermediate steps, starting from step 1, leading up to the final construction\.',
        f'I need to continue from step {k+1} and generate images of the remaining steps to complete the final construction.',
        second_question
    )
    
    second_obj["Question"] = second_question
    
    # problem_image_1: ä¿æŒåŸå§‹çš„final state
    second_obj["problem_image_1"] = obj["problem_image_1"]
    
    # problem_image_2: æ”¹ä¸ºstep kçš„å›¾ç‰‡ï¼ˆä½œä¸ºæ–°çš„èµ·å§‹çŠ¶æ€ï¼‰
    step_k_key = f"reasoning_image_{k}"
    if step_k_key in obj:
        second_obj["problem_image_2"] = obj[step_k_key]
    
    # Text Reasoning Trace: å‰©ä½™çš„æ¨ç†æ­¥éª¤ï¼Œé‡æ–°ç¼–å·
    second_reasoning = " ".join(second_chunks).strip()
    
    # åˆ›å»ºreasoning_imageçš„æ˜ å°„
    old_to_new = {}
    new_r_idx = 1
    for rk in reasoning_keys:
        m = pat_reasoning.match(rk)
        if m:
            old_idx = int(m.group(1))
            if old_idx > k:
                old_to_new[old_idx] = new_r_idx
                new_key = f"reasoning_image_{new_r_idx}"
                second_obj[new_key] = obj[rk]
                new_r_idx += 1
    
    # é‡æ–°ç¼–å·THOUGHT, Step, reasoning_image
    second_reasoning = renumber_thoughts(second_reasoning, start_num=0)
    second_reasoning = renumber_steps(second_reasoning, start_num=k+1)
    second_reasoning = renumber_reasoning_images(second_reasoning, old_to_new)
    
    second_obj["Text Reasoning Trace"] = second_reasoning
    
    # Final Answer
    if "Final Answer" in obj:
        second_obj["Final Answer"] = obj["Final Answer"]
    
    # ä¿ç•™å…ƒæ•°æ®
    for meta_key in ["category", "subcategory", "scene_name", "blocks"]:
        if meta_key in obj:
            first_obj[meta_key] = obj[meta_key]
            second_obj[meta_key] = obj[meta_key]
    
    return [first_obj, second_obj]

def process_file(input_path: Path):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶è¿”å›æ‰€æœ‰æ•°æ®å’ŒçŸ­æ•°æ®"""
    total = 0
    skipped = 0
    split_count = 0
    all_data = []
    short_data = []  # åªåŒ…å«åŸå§‹æ¨ç†æ­¥æ•°<11çš„æ•°æ®
    
    with input_path.open("r", encoding="utf-8") as fin:
        for line_num, line in enumerate(fin, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                obj = json.loads(line)
            except json.JSONDecodeError:
                print(f"âš ï¸ Line {line_num} JSON decode error â€” skip.")
                skipped += 1
                continue
            
            total += 1
            
            # åœ¨å¤„ç†ä¹‹å‰ï¼Œæ£€æŸ¥åŸå§‹æ¨ç†æ­¥æ•°
            original_reasoning_keys = collect_reasoning_keys(obj)
            original_y = len(original_reasoning_keys)
            
            result = process_line(obj)
            
            if result is None:
                skipped += 1
                continue
            
            if len(result) == 1:
                all_data.append(result[0])
                # åªæœ‰åŸå§‹æ¨ç†æ­¥æ•°<11çš„æ‰åŠ å…¥short_data
                if original_y < 11:
                    short_data.append(result[0])
            else:
                # åˆ†å‰²æˆä¸¤éƒ¨åˆ†
                all_data.append(result[0])
                all_data.append(result[1])
                # åŸå§‹æ•°æ®è¢«åˆ†å‰²äº†ï¼Œè¯´æ˜åŸå§‹æ¨ç†æ­¥æ•°>=11ï¼Œä¸åŠ å…¥short_data
                split_count += 1
    
    return all_data, short_data, total, skipped, split_count


def main():
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    train_dir = BASE_DIR / "train_minimal"
    bench_dir = BASE_DIR / "bench_minimal"
    train_short_dir = BASE_DIR / "train_short_minimal"
    train_dir.mkdir(exist_ok=True)
    bench_dir.mkdir(exist_ok=True)
    train_short_dir.mkdir(exist_ok=True)
    
    print(f"Processing minimal version (2 problem images only)")
    print(f"Processing {len(VIEWS_TO_PROCESS)} views and all_views file...")
    print(f"Using {len(BENCH_SCENES)} predefined bench scenes\n")
    
    # å¤„ç†æ‰€æœ‰è§†è§’æ–‡ä»¶
    all_files = {
        "all_views": BASE_DIR / "semantic_training_all_views_minimal.jsonl"
    }
    for view_num in VIEWS_TO_PROCESS:
        all_files[f"view{view_num}"] = BASE_DIR / f"semantic_training_view{view_num}_minimal.jsonl"
    
    for file_key, input_path in all_files.items():
        if not input_path.exists():
            print(f"âš ï¸ File not found: {input_path}")
            continue
        
        print(f"ğŸ“„ Processing {file_key}: {input_path.name}")
        
        # å¤„ç†æ–‡ä»¶
        all_data, short_data, total, skipped, split_count = process_file(input_path)
        
        # å®šä¹‰æœ€å¤§å›¾ç‰‡æ•°é™åˆ¶
        MAX_IMAGES = 20
        
        print(f"   âœ… Total input lines: {total}")
        print(f"   âœ… Lines written: {len(all_data)}")
        print(f"   âš ï¸ Lines skipped: {skipped}")
        print(f"   ğŸ“Š Lines split into 2 parts: {split_count}")
        print(f"   ğŸ“ Short data (original y<11): {len(short_data)}")
        
        # åˆ’åˆ†trainå’Œbenchï¼ŒåŒæ—¶è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
        train_data = []
        bench_data = []
        train_short_data = []
        filtered_by_images = 0
        
        for item in all_data:
            # ç»Ÿè®¡å›¾ç‰‡æ•°é‡
            num_images = len([k for k in item.keys() if 'image' in k])
            
            # è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
            if num_images > MAX_IMAGES:
                filtered_by_images += 1
                continue
            
            category = item.get("category", "")
            scene_name = item.get("scene_name", "")
            
            if (category, scene_name) in BENCH_SCENES:
                bench_data.append(item)
            else:
                train_data.append(item)
        
        # train_shortåªåŒ…å«åŸå§‹æ¨ç†æ­¥æ•°<11ä¸”ä¸åœ¨benchä¸­çš„æ•°æ®
        for item in short_data:
            # ç»Ÿè®¡å›¾ç‰‡æ•°é‡
            num_images = len([k for k in item.keys() if 'image' in k])
            
            # è¿‡æ»¤æ‰å›¾ç‰‡è¿‡å¤šçš„æ ·æœ¬
            if num_images > MAX_IMAGES:
                continue
            
            category = item.get("category", "")
            scene_name = item.get("scene_name", "")
            
            if (category, scene_name) not in BENCH_SCENES:
                train_short_data.append(item)
        
        print(f"   ğŸ—‘ï¸ Filtered by image count (>{MAX_IMAGES}): {filtered_by_images}")
        
        # ä¿å­˜trainæ–‡ä»¶
        train_file = train_dir / f"semantic_training_{file_key}_minimal.jsonl"
        with train_file.open("w", encoding="utf-8") as f:
            for item in train_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        print(f"   âœ… Train set: {len(train_data)} samples â†’ {train_file}")
        
        # ä¿å­˜benchæ–‡ä»¶
        bench_file = bench_dir / f"semantic_training_{file_key}_minimal.jsonl"
        with bench_file.open("w", encoding="utf-8") as f:
            for item in bench_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        print(f"   âœ… Bench set: {len(bench_data)} samples â†’ {bench_file}")
        
        # ä¿å­˜train_shortæ–‡ä»¶
        train_short_file = train_short_dir / f"semantic_training_{file_key}_minimal.jsonl"
        with train_short_file.open("w", encoding="utf-8") as f:
            for item in train_short_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        print(f"   âœ… Train short set (y<11): {len(train_short_data)} samples â†’ {train_short_file}")
        print()
    
    print(f"ğŸ‰ All done!")
    print(f"ğŸ“ Train files saved to: {train_dir}")
    print(f"ğŸ“ Bench files saved to: {bench_dir}")
    print(f"ğŸ“ Train short files (y<11) saved to: {train_short_dir}")

if __name__ == "__main__":
    main()
    '''
python split_semantic_data_minimal.py
'''
